{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SetUp Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('C:/Users/sandi/spark-2.4.3-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/sandi/spark-2.4.3-bin-hadoop2.7'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, explode, desc, lit, row_number, array\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark config\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"recommender system\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.master\", \"local[2]\") \\\n",
    "    .getOrCreate()\n",
    "# get spark context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario1: Build a model for batch prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains data with book_id, cust_id and rating using\n",
    "ratings = spark.read.load('D:/Code/Recommender system/datasets/book_ratings.csv', format='csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|book_id|cust_id|rating|\n",
      "+-------+-------+------+\n",
      "|613    |49452  |5     |\n",
      "|606    |22007  |1     |\n",
      "|235    |72296  |3     |\n",
      "+-------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+\n",
      "|summary|          book_id|           cust_id|            rating|\n",
      "+-------+-----------------+------------------+------------------+\n",
      "|  count|           100000|            100000|            100000|\n",
      "|   mean|        500.44013|       50011.57292|           2.99959|\n",
      "| stddev|288.4549640034758|23104.453942277418|1.4147614100612311|\n",
      "|    min|                1|             10001|                 1|\n",
      "|    max|             1000|             90000|                 5|\n",
      "+-------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct customer Ids: 57072\n",
      "Distinct book Ids: 1000\n"
     ]
    }
   ],
   "source": [
    "# No of dictinct customer Ids and Book Ids\n",
    "print(\"Distinct customer Ids: {}\".format(ratings.select('cust_id').distinct().count()))\n",
    "print(\"Distinct book Ids: {}\".format(ratings.select('book_id').distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|rating|\n",
      "+------+\n",
      "|     1|\n",
      "|     2|\n",
      "|     3|\n",
      "|     4|\n",
      "|     5|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distinct ratings\n",
    "ratings.select('rating').distinct().sort('rating').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses cross validator with hyperparameter space and k-fold validation to train the model. \n",
    "# Due to k-fold cross validation this was taking longer time. It appeared it would take longer time during demo therefore\n",
    "# I only used the one with hyper parameter space. i.e. the function - train_model_als.\n",
    "def train_model_als_csv(data, num_iters, reg_params, ranks, train_split, params, num_folds):\n",
    "    (train_data, validation_data) = data.randomSplit([train_split, 1 - train_split])\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "    als = ALS(userCol = params['userCol'], itemCol = params['itemCol'], ratingCol = params['ratingCol'], seed = 101, coldStartStrategy = \"drop\")\n",
    "    paramGrid = ParamGridBuilder().addGrid(als.rank, ranks).addGrid(als.maxIter, [num_iters]).addGrid(als.regParam, reg_params).build()\n",
    "    crossval = CrossValidator(estimator=als, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=num_folds)\n",
    "    cvModel = crossval.fit(train_data)\n",
    "    predictions = cvModel.transform(validation_data)\n",
    "    print (\"The root mean squared error for final model is: \" + str(evaluator.evaluate(predictions.na.drop())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output - RMSE score\n",
    "# Input - validation or test data. Validation data has been used to arrive at optimal model parameters. \n",
    "# The optimal\\best model is then used with the test data\n",
    "# label_col - original ground truth data\n",
    "# prediction_col - prediction made by the model\n",
    "def get_rmse_score(test_data, model, label_col, prediction_col):\n",
    "    predictions = model.transform(test_data)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol = label_col, predictionCol=prediction_col)\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output - Model based on multiple input parameters below\n",
    "# data - Pyspark dataframe containing training data\n",
    "# num_iters - No of iterations that ALS algorithm would run\n",
    "# ranks - Latent factor\n",
    "# train_split - It's a number between 0 and 1 based on which it would split the train & validation/test data\n",
    "# params is a dictionary with the format {userCol: userId, itemCol: movieId, ratingCol: rating}\n",
    "def train_model_als(data, num_iters, reg_params, ranks, train_split, params):\n",
    "    if train_split <=0 and train_split >=1:\n",
    "        print (\"The split is not valid\")\n",
    "        return None\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        for reg in reg_params:\n",
    "            als = ALS(maxIter = num_iters, regParam = reg, userCol = params['userCol'], itemCol = params['itemCol'], ratingCol = params['ratingCol'], rank=rank, seed = 101, coldStartStrategy = \"drop\")\n",
    "            (train_data, validation_data) = data.randomSplit([train_split, 1 - train_split])\n",
    "            model = als.fit(train_data)\n",
    "            rmse = get_rmse_score(validation_data, model, \"rating\", \"prediction\")\n",
    "            print (\"Latent factor: {} L2 reg: {} RMSE: {}\".format(rank, reg, rmse))\n",
    "            if  rmse < min_error:\n",
    "                min_error = rmse\n",
    "                final_rank = rank\n",
    "                final_reg_param = reg\n",
    "                final_model = model\n",
    "    print(\"Final model params:: latent factors {}, regularization = {}, RMSE = {}\".format(final_rank, final_reg_param, min_error)) \n",
    "    return final_model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the best model by passing multiple hyper-parameters to the function - train_model_als\n",
    "# Note: For demo purpose, I've used limited hyper-params in the hyper parameter space. Ideally it should be trained on bigger set \n",
    "# params is a dictionary with the format {userCol: userId, itemCol: movieId, ratingCol: rating}\n",
    "def get_best_model(train_data, params):\n",
    "    num_iterations = 5\n",
    "    ranks = [5, 10, 20]\n",
    "    reg_params = [0.001, 0.01, 1.0]\n",
    "    start_time = time.time()\n",
    "    # Trains the model based on hyper parameter space\n",
    "    best_model = train_model_als(train_data, num_iterations, reg_params, ranks, 0.8, params)\n",
    "    # Uses k-fold cross validation with hyper parameter space for training\n",
    "    # best_model = train_model_als_csv(train_data, num_iterations, reg_params, ranks, 0.8, params, 5)\n",
    "    print ('Total Runtime: {:.2f} seconds'.format(time.time() - start_time))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent factor: 5 L2 reg: 0.001 RMSE: 4.358051925856775\n",
      "Latent factor: 5 L2 reg: 0.01 RMSE: 4.103991750133299\n",
      "Latent factor: 5 L2 reg: 1.0 RMSE: 3.39363214894107\n",
      "Latent factor: 10 L2 reg: 0.001 RMSE: 3.6223317557045247\n",
      "Latent factor: 10 L2 reg: 0.01 RMSE: 3.576915439846166\n",
      "Latent factor: 10 L2 reg: 1.0 RMSE: 3.284929082656895\n",
      "Latent factor: 20 L2 reg: 0.001 RMSE: 3.40146577924521\n",
      "Latent factor: 20 L2 reg: 0.01 RMSE: 3.393262669058938\n",
      "Latent factor: 20 L2 reg: 1.0 RMSE: 3.314399992140276\n",
      "Final model params:: latent factors 10, regularization = 1.0, RMSE = 3.284929082656895\n",
      "Total Runtime: 867.94 seconds\n"
     ]
    }
   ],
   "source": [
    "# Output: Calls the get_best_model function to get the optimal\\best model that will be used for prediction\n",
    "# 80% of the data is used for training and 20% for testing \n",
    "(train_data, test_data) = ratings.randomSplit([0.8, 0.2])\n",
    "best_model = get_best_model(train_data, {'userCol': 'cust_id', 'itemCol': 'book_id', 'ratingCol': 'rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: Predicts top n item recommendations for each User\n",
    "# Input: final model, data - test data, num_items - returns the no of items for each user\n",
    "def predict_top_n_items(best_model, data, num_items):\n",
    "    best_model.transform(data)\n",
    "    return best_model.recommendForAllUsers(num_items)\n",
    "\n",
    "# Predicts top n user recommendations for each item\n",
    "# Input: final model, data - test data, num_users - returns the no of user for each item\n",
    "def predict_top_n_users(best_model, data, num_users):\n",
    "    best_model.transform(data)\n",
    "    return best_model.recommendForAllItems(num_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------------------------------------------------------------------+\n",
      "|cust_id|recommendations                                                                            |\n",
      "+-------+-------------------------------------------------------------------------------------------+\n",
      "|11141  |[[881, 1.4347032], [172, 1.2989947], [404, 1.1880406], [357, 1.1697912], [992, 1.1179773]] |\n",
      "|11317  |[[757, 3.4713113], [744, 3.2671514], [674, 3.124947], [37, 3.022014], [655, 2.9587038]]    |\n",
      "|11458  |[[223, 2.8591177], [43, 2.3309672], [82, 2.242475], [248, 2.198267], [239, 2.1922367]]     |\n",
      "|11858  |[[944, 2.7403433], [659, 2.717301], [154, 2.4282458], [896, 2.4180899], [981, 2.3945622]]  |\n",
      "|12046  |[[537, 0.6584311], [629, 0.6234269], [141, 0.6159075], [508, 0.6124771], [465, 0.58440864]]|\n",
      "+-------+-------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Output: Pyspark dataframe containing Customer Id and list of recommendationsi.e [book_id, rating]\n",
    "# Input: Model, test data & no of recommendations \n",
    "top_5_items_df = predict_top_n_items(best_model, test_data, 5)\n",
    "top_5_items_df.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output returns: first element of every lists within a list\n",
    "# Input: Lists of lists\n",
    "def return_item_data(list_recommendations):\n",
    "    temp_list = []\n",
    "    for item in list_recommendations:\n",
    "        temp_list.append(item[0])\n",
    "    return temp_list\n",
    "\n",
    "# Output: Dataframe with customer Id and list of items. THis removes the raring from the above dataframe  \n",
    "def get_user_movie_recommendation(function, df):\n",
    "    get_list_udf = udf(function, ArrayType(IntegerType()))\n",
    "    user_item_df = df.withColumn('list_items', get_list_udf(df.recommendations)).drop('recommendations')\n",
    "    return user_item_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------+\n",
      "|cust_id|list_items               |\n",
      "+-------+-------------------------+\n",
      "|11141  |[881, 172, 404, 357, 992]|\n",
      "|11317  |[757, 744, 674, 37, 655] |\n",
      "|11458  |[223, 43, 82, 248, 239]  |\n",
      "|11858  |[944, 659, 154, 896, 981]|\n",
      "|12046  |[537, 629, 141, 508, 465]|\n",
      "+-------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calls get_user_movie_recommendation and displays the result\n",
    "user_item_df = get_user_movie_recommendation(return_item_data, top_5_items_df)\n",
    "user_item_df.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for test data is 3.334720511198201\n"
     ]
    }
   ],
   "source": [
    "# RMSE is calculated for the test data. Note the higher RMSE is attributed to the randomness of the data\n",
    "rmse_test_data = get_rmse_score(test_data, best_model, \"rating\", \"prediction\")\n",
    "print(\"RMSE for test data is {}\".format(rmse_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario 2: Offline Model Training. This is a scenario where few users (whose UserId is not yet created) have provided their preference by giving book name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigns a user_id  to the new User\n",
    "def generate_new_id(df, user_id_column):\n",
    "    max_user_id = df.agg({user_id_column: \"max\"}).collect()[0]['max(' + user_id_column + ')'] + 1\n",
    "    return max_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data consists of Username and Book Name\n",
    "user_pref_df = spark.read.load('D:/Code/Recommender system/datasets/user_pref_books.csv', format='csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|username|book_name     |\n",
      "+--------+--------------+\n",
      "|Arvind  |Robert Garcia |\n",
      "|Mac     |Michael Rivera|\n",
      "|Alan    |Jaime Palmer  |\n",
      "|Ram     |Matthew Jones |\n",
      "|Ankit   |Adam Wright   |\n",
      "+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_pref_df.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "|book_name        |book_id|\n",
      "+-----------------+-------+\n",
      "|Juan Jimenez     |334    |\n",
      "|Sharon George    |192    |\n",
      "|Alexandra Stanley|786    |\n",
      "+-----------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This dataframe contains book name and book Id. **** Please pardon me for the book names listed here :) *************\n",
    "books_df = spark.read.load('D:/Code/Recommender system/datasets/book.csv', format='csv', header=True, inferSchema=True)\n",
    "books_df.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: returns dataframe with userId, rating and movieId for the new User. This data will then be used to train the model.\n",
    "# Adds userId and ItemId to the user preference dataset\n",
    "def preparing_rating_dataset(ratings_df, user_pref_df, item_df, user_id_column):\n",
    "    # Add new column: userId\n",
    "    max_user_id = ratings_df.agg({user_id_column: \"max\"}).collect()[0]['max(' + user_id_column + ')']\n",
    "    w = Window.orderBy(\"userName\")\n",
    "    user_item_df = user_pref_df.withColumn(user_id_column, row_number().over(w) + max_user_id).withColumn(\"rating\", lit(4))\n",
    "    # Add ItemId\n",
    "    rating_new_df = user_item_df.join(item_df, user_item_df.book_name == item_df.book_name,'inner').drop('book_name').drop('username')\n",
    "    return rating_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|cust_id|rating|book_id|\n",
      "+-------+------+-------+\n",
      "|  90008|     4|    867|\n",
      "|  90014|     4|     51|\n",
      "|  90008|     4|    940|\n",
      "+-------+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_rating_df = preparing_rating_dataset(ratings, user_pref_df,books_df, 'cust_id')\n",
    "new_rating_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrains the model by adding the new user data to the original train dataset\n",
    "def retrain_model(train_df, user_pref_df):\n",
    "    updated_train_df = train_df.drop('timestamp').union(user_pref_df)\n",
    "    best_model = get_best_model(updated_train_df, {'userCol': 'cust_id', 'itemCol': 'book_id', 'ratingCol': 'rating'})\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent factor: 5 L2 reg: 0.001 RMSE: 8.925741439535976\n",
      "Latent factor: 5 L2 reg: 0.01 RMSE: 12.105380792286928\n",
      "Latent factor: 5 L2 reg: 1.0 RMSE: 8.039010302992763\n",
      "Latent factor: 10 L2 reg: 0.001 RMSE: 10.981460498230357\n",
      "Latent factor: 10 L2 reg: 0.01 RMSE: 11.69551318316286\n",
      "Latent factor: 10 L2 reg: 1.0 RMSE: 9.0794303338148\n",
      "Latent factor: 20 L2 reg: 0.001 RMSE: 8.869672626283183\n",
      "Latent factor: 20 L2 reg: 0.01 RMSE: 11.483837170466234\n",
      "Latent factor: 20 L2 reg: 1.0 RMSE: 8.81810943018907\n",
      "Final model params:: latent factors 5, regularization = 1.0, RMSE = 8.039010302992763\n",
      "Total Runtime: 725.62 seconds\n"
     ]
    }
   ],
   "source": [
    "updated_model = retrain_model(train_data, new_rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario3: Cold Start problem. ALS Matrix factorization works for users who have rated the items\\books. It will not be handled for new users. The idea is to assign the top 10 popular items to each User and keep shuffling between them while displaying the items to the User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns top n popular items from the ratings dataframe. \n",
    "def get_n_popular_items(ratings_df, n):\n",
    "    item_grouped_df = ratings_df.groupBy('book_id').count().sort('count', ascending=False).take(n)\n",
    "    popular_book_id = []\n",
    "    for row in item_grouped_df:\n",
    "        popular_book_id.append(lit(row['book_id']))\n",
    "    return popular_book_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Column<b'662'>, Column<b'234'>, Column<b'247'>, Column<b'374'>, Column<b'739'>]\n"
     ]
    }
   ],
   "source": [
    "n_popular_items = get_n_popular_items(ratings,5)\n",
    "print (n_popular_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file consists of new set of users with customer Id and Customer name\n",
    "new_users_df = spark.read.load('D:/Code/Recommender system/datasets/new_users.csv', format='csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|cust_id|cust_name    |\n",
      "+-------+-------------+\n",
      "|95022  |Thomas Thomas|\n",
      "|96635  |Renee Brooks |\n",
      "+-------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_users_df.show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-------------------------+\n",
      "|cust_id|cust_name      |recommended_books        |\n",
      "+-------+---------------+-------------------------+\n",
      "|95022  |Thomas Thomas  |[662, 234, 247, 374, 739]|\n",
      "|96635  |Renee Brooks   |[662, 234, 247, 374, 739]|\n",
      "|96201  |Shannon Perez  |[662, 234, 247, 374, 739]|\n",
      "|95788  |Gloria Williams|[662, 234, 247, 374, 739]|\n",
      "|96296  |Craig Lopez    |[662, 234, 247, 374, 739]|\n",
      "+-------+---------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# returns list of popular books against each User\n",
    "new_users_recommended_books=new_users_df.withColumn(\"recommended_books\", array(n_popular_items))\n",
    "new_users_recommended_books.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
